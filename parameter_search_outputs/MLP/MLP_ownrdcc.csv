,number units,L2 regularization,learning rate,beta 1,beta 2,accuracy,balanced accuracy,ROC,F1,Matthews
model 0,148.39587789946515,0.007135971223420317,0.007161773284470585,0.8846108626771478,0.8846108626771478,0.9626416490130806,0.7439280848488566,0.7439280848488566,0.9803686556288809,0.6178565987909651
model 1,117.20485645441985,0.005404869533220302,0.005446267104993093,0.8154707651406307,0.8154707651406307,0.9628097784054607,0.7145648641539908,0.7145648641539908,0.9805392746760733,0.6068053595614389
model 2,109.53152269435945,0.0049789995095369495,0.005024233748189771,0.7984615419724967,0.7984615419724967,0.9562863579811022,0.6516249497044807,0.6516249497044807,0.9772722404812599,0.4172746788302318
best model,0.7382970869191422,0.007135971223420317,0.007161773284470585,0.8846108626771478,0.8846108626771478,0.963407973784817,0.7456310024989781,0.7456310024989781,0.9807305148116191,0.6505828503260299
