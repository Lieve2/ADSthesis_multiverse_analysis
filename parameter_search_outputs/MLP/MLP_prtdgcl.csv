,number units,L2 regularization,learning rate,beta 1,beta 2,accuracy,balanced accuracy,ROC,F1,Matthews
model 0,51.45770451578623,0.0017559026006261362,0.001830173748368243,0.6697312450099928,0.6697312450099928,0.6847237634083191,0.6801619735264183,0.6801619735264185,0.6382426200995607,0.36012581701468743
model 1,100.68809990846054,0.00448818954491956,0.004537845494965331,0.7788586214637542,0.7788586214637542,0.6828743400921349,0.6809183164149194,0.6809183164149196,0.6442164884159588,0.3603526009212617
model 2,82.43136820639322,0.003474940935454824,0.003533725251351627,0.738389532857505,0.738389532857505,0.6874138336864051,0.6815951820549185,0.6815951820549185,0.637986682848809,0.36330157550049885
best model,0.4101113850262727,0.003474940935454824,0.003533725251351627,0.738389532857505,0.738389532857505,0.6775669033315128,0.6775319157338441,0.677531915733844,0.6415724368217347,0.35165435280992124
