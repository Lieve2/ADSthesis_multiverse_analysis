,number units,L2 regularization,learning rate,beta 1,beta 2,accuracy,balanced accuracy,ROC,F1,Matthews
model 0,100.68809990846054,0.00448818954491956,0.004537845494965331,0.7788586214637542,0.7788586214637542,0.9986885907394331,0.9969860178234905,0.9969860178234905,0.9991627597698948,0.9961469101663895
model 1,190.0723449307682,0.009449015143657634,0.009453978971192252,0.9769936979298695,0.9769936979298695,0.9266619590436801,0.8314574171479068,0.8314574171479069,0.9587916516060956,0.6641969326546181
model 2,100.68809990846054,0.00448818954491956,0.004537845494965331,0.7788586214637542,0.7788586214637542,0.9986885907394331,0.9969860178234905,0.9969860178234905,0.9991627597698948,0.9961469101663895
best model,0.5009420201024862,0.00448818954491956,0.004537845494965331,0.7788586214637542,0.7788586214637542,0.9984980884762424,0.997002393355537,0.997002393355537,0.9990407255603034,0.9955866328869377
