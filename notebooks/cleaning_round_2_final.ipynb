{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from utility_functions import random_imputation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('ESS8 data/ESS8_cleaned_wmissingvals.csv', low_memory=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make df with missingness percentage of features with missingness\n",
    "missing_cols = data.columns[data.isnull().any()].to_list()\n",
    "percent_missing = data[missing_cols].isnull().sum() * 100 / len(data)\n",
    "missing_info = pd.DataFrame({'column name':missing_cols,\n",
    "                             'percentage missing':percent_missing})\n",
    "\n",
    "# extract rows with >= 70% missing\n",
    "many_missing = missing_info[missing_info['percentage missing'] > 70]\n",
    "many_missing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternative to standard correlation heatmap: https://towardsdatascience.com/better-heatmaps-and-correlation-matrix-plots-in-python-41445d0f2bec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## remove features with >70% missing and with one value in entire data set\n",
    "many_missing_feat = many_missing.index.tolist()\n",
    "\n",
    "df_cleaned_missing = data.drop(columns=many_missing_feat)\n",
    "for col in df_cleaned_missing.columns:\n",
    "    if len(df_cleaned_missing[col].unique()) == 1:\n",
    "        df_cleaned_missing.drop(col, inplace=True, axis=1)\n",
    "nr_feat = len(df_cleaned_missing.columns)\n",
    "print(f\"Number of features after removing >70% missing and 1-value features: {nr_feat}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check cleaning results\n",
    "df_cleaned_missing.nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check cleaning results\n",
    "df_cleaned_missing.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "v = df_cleaned_missing.idno.value_counts()\n",
    "df_cleaned_missing[df_cleaned_missing.idno.isin(v.index[v.gt(2)])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ID number has identical values, but this does not look informative and hence is removed\n",
    "print(df_cleaned_missing[df_cleaned_missing['idno'] == 1304])\n",
    "\n",
    "# remove idno column from data\n",
    "df_cleaned_missing = df_cleaned_missing.drop(columns=['idno'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check what and how many other years are present in the data\n",
    "df_cleaned_missing[df_cleaned_missing['inwyye'] != 2016.0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save new data set\n",
    "df_cleaned_missing.to_csv('ESS8 data/ESS8_subset_cleaned_wmissingvals.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# encode object type data\n",
    "enc = OrdinalEncoder()\n",
    "data_obj = df_cleaned_missing.select_dtypes(include=object)\n",
    "enc.fit(data_obj)\n",
    "encoding = enc.fit_transform(data[data_obj.columns])\n",
    "\n",
    "c = 0\n",
    "\n",
    "for i in data_obj.columns:\n",
    "    df_cleaned_missing[i] = encoding[:, c]\n",
    "    c += 1\n",
    "\n",
    "df_cleaned_missing.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_cleaned_missing[df_cleaned_missing[['inwtm']].isnull().any(axis=1)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# if the end year is missing then there is a start year and vice versa, so fill with each other\n",
    "df_cleaned_missing['inwyye'] = df_cleaned_missing['inwyye'].fillna(df_cleaned_missing['inwyys'])\n",
    "df_cleaned_missing['inwyys'] = df_cleaned_missing['inwyys'].fillna(df_cleaned_missing['inwyye'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# replace 0 with 24 and calculate total time\n",
    "df_cleaned_missing['inwshh'].replace(0, 24, inplace=True)\n",
    "df_cleaned_missing['inwehh'].replace(0, 24, inplace=True)\n",
    "df_cleaned_missing[df_cleaned_missing[['inwtm']].isnull().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this could be done once after random imputation but keep it here to check percentage/nr rows still missing\n",
    "df_cleaned_missing['inwtm'] = df_cleaned_missing['inwtm'].fillna(abs((df_cleaned_missing['inwehh'].mul(60) +\n",
    "                                                                  df_cleaned_missing['inwemm']) -\n",
    "                                                                 (df_cleaned_missing['inwshh'].mul(60) +\n",
    "                                                                  df_cleaned_missing['inwsmm'])))\n",
    "\n",
    "df_cleaned_missing[df_cleaned_missing[['inwtm']].isnull().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# random imputation\n",
    "df_cleaned_missing['inwtm'] = random_imputation(df_cleaned_missing['inwtm'].to_frame())\n",
    "\n",
    "df_cleaned_missing['inwtm'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#no missing values in inwtm anymore :)\n",
    "df_cleaned_missing[df_cleaned_missing[['inwtm']].isnull().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# drop other interview time data (so except year and month)\n",
    "df_cleaned_missing.drop(['inwemm', 'inwehh', 'inwsmm', 'inwshh'], axis=1, inplace=True) #remove columns with all identical vals\n",
    "# df_cleaned_missing.shape()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check how many missing months and days\n",
    "missing_endmo = len(df_cleaned_missing[df_cleaned_missing[['inwmme']].isnull().any(axis=1)])\n",
    "missing_enddy = len(df_cleaned_missing[df_cleaned_missing[['inwdde']].isnull().any(axis=1)])\n",
    "missing_stamo = len(df_cleaned_missing[df_cleaned_missing[['inwmms']].isnull().any(axis=1)])\n",
    "missing_stady = len(df_cleaned_missing[df_cleaned_missing[['inwdds']].isnull().any(axis=1)])\n",
    "\n",
    "print(f\"\"\"nr missing month end: {missing_endmo}\\n\n",
    "nr missing day end: {missing_enddy}\\n\n",
    "nr missing month start: {missing_stamo}\\n\n",
    "nr missing day start: {missing_stady}\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# not many missing in month and day columns, so use random imputation\n",
    "df_cleaned_missing['inwmme'] = random_imputation(df_cleaned_missing['inwmme'].to_frame())\n",
    "df_cleaned_missing['inwdde'] = random_imputation(df_cleaned_missing['inwdde'].to_frame())\n",
    "df_cleaned_missing['inwmms'] = random_imputation(df_cleaned_missing['inwmms'].to_frame())\n",
    "df_cleaned_missing['inwdds'] = random_imputation(df_cleaned_missing['inwdds'].to_frame())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check if numerical features have missingness; they do !!!\n",
    "df_cleaned_missing[df_cleaned_missing[['dweight', 'pspwght','pweight', 'anweight', 'nwspol',\n",
    "            'netustm','agea', 'eduyrs', 'wkhct', 'wkhtot',\n",
    "            'wkhtotp', 'inwtm']].isnull().any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save cleaned data to csv file\n",
    "df_cleaned_missing.to_csv('ESS8 data/ESS8_subset_cleaned_timeadj_wmissingvals.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below, some initial checks are done to gain insight into what data sets will be constructed\n",
    "during the processing pipeline."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## check if loading the data works and extract all targets (i.e. >5% missing)\n",
    "\n",
    "# load data\n",
    "data3 = pd.read_csv('ESS8 data/ESS8_subset_cleaned_timeadj_wmissingvals.csv', low_memory=False)\n",
    "\n",
    "# make df with missingness percentage of features with missingness\n",
    "missing_cols = data3.columns[data3.isnull().any()].to_list()\n",
    "percent_missing = data3[missing_cols].isnull().sum() * 100 / len(data3)\n",
    "missing_info = pd.DataFrame({'column name':missing_cols,\n",
    "                             'percentage missing':percent_missing})\n",
    "\n",
    "# extract rows with > 5% missing (74 features)\n",
    "many_missing = missing_info[missing_info['percentage missing'] > 5]\n",
    "# print(len(many_missing))\n",
    "\n",
    "targets3 = many_missing['column name'].tolist()\n",
    "targets3\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}